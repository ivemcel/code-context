import {
    CodeIndexer,
    MilvusVectorDatabase,
    OllamaEmbedding,
    // Uncomment to use OpenAI or VoyageAI
    OpenAIEmbedding,
    VoyageAIEmbedding,
    AstCodeSplitter,
    StarFactoryEmbedding,
    Qwen3Embedding,
    MilvusRestfulVectorDatabase,
    EmbeddingVector
} from '@code-indexer/core';
import { EnhancedAstSplitter } from '@code-indexer/core/src/splitter/enhanced-ast-splitter';
import * as path from 'path';
import * as fs from 'fs';
import * as os from 'os';

// Try to load .env file
try {
    require('dotenv').config();
} catch (error) {
    // dotenv is not required, skip if not installed
}

// Custom rate-limited embedding wrapper for VoyageAI (free tier: 3 RPM, 10K TPM)
class RateLimitedVoyageEmbedding extends VoyageAIEmbedding {
    private lastEmbedTime: number = 0;
    private embeddingQueue: Array<{
        texts: string[],
        resolve: (value: EmbeddingVector[]) => void,
        reject: (reason: any) => void
    }> = [];
    private processingQueue: boolean = false;
    private tokenCount: number = 0;
    private tokenResetTimeout: NodeJS.Timeout | null = null;
    private requestCount: number = 0;
    private requestResetTimeout: NodeJS.Timeout | null = null;
    
    // Conservative rate limits for free tier
    private readonly MIN_REQUEST_DELAY_MS: number = 25000; // 25 seconds between requests (conservative)
    private readonly MAX_REQUESTS_PER_MINUTE: number = 2; // Limit to 2 per minute to be safe
    private readonly MAX_TOKENS_PER_MINUTE: number = 9000; // Keep under 10K TPM limit
    private readonly MAX_BATCH_SIZE: number = 2; // Small batch size to reduce chances of hitting limits

    constructor(config: any) {
        super(config);
        console.log('üïí Using strict rate-limited VoyageAI embedding (enforce 25s between requests)');
        
        // Reset token count every minute
        this.resetTokenCounter();
        this.resetRequestCounter();
    }

    private resetTokenCounter() {
        if (this.tokenResetTimeout) {
            clearTimeout(this.tokenResetTimeout);
        }
        
        this.tokenResetTimeout = setTimeout(() => {
            console.log(`üîÑ Resetting token count (was ${this.tokenCount})`);
            this.tokenCount = 0;
            this.resetTokenCounter();
            // Process any pending requests
            this.processQueue();
        }, 60 * 1000); // 1 minute
    }
    
    private resetRequestCounter() {
        if (this.requestResetTimeout) {
            clearTimeout(this.requestResetTimeout);
        }
        
        this.requestResetTimeout = setTimeout(() => {
            console.log(`üîÑ Resetting request count (was ${this.requestCount})`);
            this.requestCount = 0;
            this.resetRequestCounter();
            // Process any pending requests
            this.processQueue();
        }, 60 * 1000); // 1 minute
    }

    // Add cleanup method to clear timers
    public cleanup() {
        if (this.tokenResetTimeout) {
            clearTimeout(this.tokenResetTimeout);
            this.tokenResetTimeout = null;
        }
        if (this.requestResetTimeout) {
            clearTimeout(this.requestResetTimeout);
            this.requestResetTimeout = null;
        }
        console.log('üßπ Cleaned up rate limiter timers');
    }

    private estimateTokens(texts: string[]): number {
        // Rough estimation: ~1 token per 4 characters
        return texts.reduce((sum, text) => sum + Math.ceil(text.length / 4), 0);
    }

    async embedBatch(texts: string[]): Promise<EmbeddingVector[]> {
        const estimatedTokens = this.estimateTokens(texts);
        
        // If this would exceed our rate limit, split into smaller batches
        if (texts.length > this.MAX_BATCH_SIZE) {
            console.log(`‚ö†Ô∏è Large batch detected (${texts.length} chunks, ~${estimatedTokens} tokens), splitting into smaller batches`);
            
            // Process in smaller batches to avoid hitting rate limits
            const batchSize = this.MAX_BATCH_SIZE; // Small batch size to stay under limits
            const results: EmbeddingVector[] = [];
            
            for (let i = 0; i < texts.length; i += batchSize) {
                const batch = texts.slice(i, i + batchSize);
                console.log(`üì¶ Processing mini-batch ${Math.floor(i/batchSize) + 1}/${Math.ceil(texts.length/batchSize)} (${batch.length} chunks)`);
                const batchResults = await this.embedBatchWithRateLimit(batch);
                results.push(...batchResults);
                
                // Always add significant delay between batches
                if (i + batchSize < texts.length) {
                    const delayMs = this.MIN_REQUEST_DELAY_MS + 5000; // Add extra 5 seconds buffer
                    console.log(`‚è±Ô∏è Adding ${delayMs/1000}s delay between batches to respect rate limits...`);
                    await new Promise(resolve => setTimeout(resolve, delayMs));
                }
            }
            
            return results;
        }
        
        return this.embedBatchWithRateLimit(texts);
    }

    private async embedBatchWithRateLimit(texts: string[]): Promise<EmbeddingVector[]> {
        return new Promise((resolve, reject) => {
            this.embeddingQueue.push({ texts, resolve, reject });
            this.processQueue();
        });
    }

    private async processQueue() {
        if (this.processingQueue || this.embeddingQueue.length === 0) {
            return;
        }

        this.processingQueue = true;
        const { texts, resolve, reject } = this.embeddingQueue.shift()!;
        
        // Estimate tokens for this request
        const estimatedTokens = this.estimateTokens(texts);
        
        // Check if this would exceed our token limit
        if (this.tokenCount + estimatedTokens > this.MAX_TOKENS_PER_MINUTE) {
            console.log(`‚è≥ Token limit reached (${this.tokenCount}+${estimatedTokens} > ${this.MAX_TOKENS_PER_MINUTE}), waiting for token counter reset...`);
            
            // Put the request back at the front of the queue
            this.embeddingQueue.unshift({ texts, resolve, reject });
            
            // Retry after the token counter resets
            this.processingQueue = false;
            return;
        }
        
        // Check if we've hit the request count limit
        if (this.requestCount >= this.MAX_REQUESTS_PER_MINUTE) {
            console.log(`‚è≥ Request limit reached (${this.requestCount} >= ${this.MAX_REQUESTS_PER_MINUTE}), waiting for request counter reset...`);
            
            // Put the request back at the front of the queue
            this.embeddingQueue.unshift({ texts, resolve, reject });
            
            // Retry after the request counter resets
            this.processingQueue = false;
            return;
        }
        
        // Check rate limit (enforce minimum delay between requests)
        const now = Date.now();
        const timeSinceLastRequest = now - this.lastEmbedTime;
        
        if (timeSinceLastRequest < this.MIN_REQUEST_DELAY_MS) {
            const waitTime = this.MIN_REQUEST_DELAY_MS - timeSinceLastRequest;
            console.log(`‚è≥ Rate limit: waiting ${waitTime/1000}s before next API call`);
            
            setTimeout(() => {
                this.processingQueue = false;
                this.processQueue();
            }, waitTime);
            
            // Put the request back at the front of the queue
            this.embeddingQueue.unshift({ texts, resolve, reject });
            return;
        }

        // Process the request
        try {
            console.log(`üî§ Processing batch of ${texts.length} texts (~${estimatedTokens} tokens)`);
            this.lastEmbedTime = now;
            this.tokenCount += estimatedTokens;
            this.requestCount++;
            
            // Call parent class implementation
            super.embedBatch(texts)
                .then(result => {
                    resolve(result);
                    this.processingQueue = false;
                    // Add fixed delay before processing next queue item
                    setTimeout(() => {
                        this.processQueue(); // Process next in queue
                    }, 2000); // Small buffer to ensure system has time to breathe
                })
                .catch(error => {
                    // If we hit a rate limit, add a long delay before retrying
                    if (error.message && error.message.includes('429')) {
                        console.error(`‚ùå Hit rate limit (429): ${error.message}`);
                        console.log('‚è±Ô∏è Adding extended delay of 60s before retrying...');
                        
                        // Put the request back in the queue to retry
                        this.embeddingQueue.unshift({ texts, resolve, reject });
                        
                        // Pause for a full minute
                        setTimeout(() => {
                            this.processingQueue = false;
                            this.processQueue();
                        }, 60000);
                    } else {
                        console.error(`‚ùå Embedding error: ${error.message}`);
                        reject(error);
                        this.processingQueue = false;
                        this.processQueue(); // Process next in queue
                    }
                });
        } catch (error) {
            console.error(`‚ùå Unexpected error in rate limiter: ${error}`);
            reject(error);
            this.processingQueue = false;
            this.processQueue(); // Process next in queue
        }
    }

    // Override embed method to use our rate-limited batch process
    async embed(text: string): Promise<EmbeddingVector> {
        const results = await this.embedBatch([text]);
        return results[0];
    }
}

async function main() {
    // ÊõøÊç¢‰∏∫‰∏≠ÂõΩÊó∂Èó¥Ê†ºÂºè (UTC+8)
    const timestamp = new Date().toLocaleString('zh-CN', {
        timeZone: 'Asia/Shanghai', 
        year: 'numeric',
        month: '2-digit',
        day: '2-digit',
        hour: '2-digit',
        minute: '2-digit',
        second: '2-digit',
        hour12: false
    }).replace(/[\/-]/g, '-').replace(/[,]/g, ' ');
    
    try {
        console.log(`[${timestamp}] ==== index codebase ÊµãËØï ====`);
        // ‰ΩøÁî®StarFactory‰Ωú‰∏∫ÈªòËÆ§ÂµåÂÖ•Ê®°Âûã
        const starFactoryApiKey = process.env.STARFACTORY_API_KEY || StarFactoryEmbedding.getDefaultApiKey();
        const starFactoryBaseURL = process.env.STARFACTORY_BASE_URL || 'http://10.142.99.29:8085';
        //const milvusAddress = process.env.MILVUS_ADDRESS || 'localhost:19530';
        const milvusToken = process.env.MILVUS_TOKEN;
        //const codebasePath = process.env.TEST_CODEBASE_PATH || '/Users/ivem/Desktop/test';
        
        //const codebasePath = "/Users/ivem/IdeaProjects/star-factory";
        //const codebasePath ="/Users/ivem/IdeaProjects/star-factory-codebase";
        //const codebasePath = "/Users/ivem/Desktop/test-qwen";
        //const codebasePath = "/Users/ivem/Desktop/test-voyage";
        //const codebasePath = "/Users/ivem/Desktop/test-starfactory";
        
        //const codebasePath = "/Users/ivem/Desktop/user-data-qwen";
        //const codebasePath = "/Users/ivem/Desktop/user-data-voyage";
        //const codebasePath = "/Users/ivem/Desktop/user-data-starfactory";

        const codebasePath = "/Users/ivem/Desktop/test";

        //const vectorDatabase = new MilvusVectorDatabase({ address: milvusAddress, ...(milvusToken && { token: milvusToken }) });
        const milvusAddress = "http://10.142.99.29:8085";
        const vectorDatabase = new MilvusRestfulVectorDatabase({ address: milvusAddress, ...(milvusToken && { token: milvusToken }) });
        // Get API key from environment variables
        const voyageApiKey = process.env.VOYAGE_API_KEY || 'pa-Weutp7FYlGyUXb8mU46hQdDcvJZhs53WJ3IWQGzszQl';

        //Use rate-limited embedding for VoyageAI to respect free tier limits
        // let embedding = new RateLimitedVoyageEmbedding({
        //     apiKey: voyageApiKey,
        //     model: 'voyage-code-3' // ‰ΩøÁî®voyage-code-3Ê®°ÂûãÔºåÈíàÂØπ‰ª£Á†Å‰ºòÂåñ
        // });
        

        // const qwen3ApiKey = "sk-3b6eca9223744941b801b4332a70a694"
        // const embedding = new Qwen3Embedding({
        //     apiKey: qwen3ApiKey,
        //     model: 'text-embedding-v4' // ÊàñËÄÖ‰ΩøÁî®mini/hugeÁâàÊú¨
        // });

        //// ‰ΩøÁî®star-factory-embedding
        const embedding = new StarFactoryEmbedding({
            baseURL: 'http://10.142.99.29:8085',
            apiKey: starFactoryApiKey
        });
        
        
        //const embedding = new OllamaEmbedding();
        // ‰ΩøÁî®Â¢ûÂº∫ÂûãASTÂàÜÂâ≤Âô®ÔºåÊîØÊåÅ‰øùÁïôÊ≥®Èáä
        const codeSplitter = new EnhancedAstSplitter(0, 0);

        // Configure very small batch size for IndexCodebase
        process.env.EMBEDDING_BATCH_SIZE = '20'; // Use smallest practical batch size
        
        const indexer = new CodeIndexer({ vectorDatabase, embedding, codeSplitter, supportedExtensions: ['.ts', '.js', '.py', '.java', '.cpp', '.go', '.rs'] });

        ////1. ÂÖ®ÈáèÁ¥¢Âºï
        console.log('1. ÊâßË°åÂÖ®ÈáèÁ¥¢Âºï...');
        try {
            // Âº∫Âà∂Ê∏ÖÈô§Áé∞ÊúâÁ¥¢ÂºïÔºåÁ°Æ‰øù‰ΩøÁî®Êñ∞‰ª£Á†ÅÂàõÂª∫
            console.log('Âº∫Âà∂Ê∏ÖÈô§Áé∞ÊúâÊú¨Âú∞Á¥¢ÂºïÊñá‰ª∂ÔºåÁ°Æ‰øù‰ΩøÁî®‰øÆÂ§çÂêéÁöÑ‰ª£Á†Å...');
            // Ê≥®ÊÑèclearIndex‰ºöÂà†Èô§ÈõÜÂêàÈáçÊñ∞ÂàõÂª∫ÔºÅÔºÅÔºÅÔºÅ‰∏¢Â§±Êï∞ÊçÆÔºÅÔºÅÔºÅÔºÅ
            await indexer.clearIndex(codebasePath);
            
            // Ê∑ªÂä†Âª∂ËøüÁ°Æ‰øùÊóßÁ¥¢ÂºïË¢´ÂÆåÂÖ®Âà†Èô§
            await new Promise(resolve => setTimeout(resolve, 2000));
            
            console.log('ÂºÄÂßãÂàõÂª∫Êñ∞Á¥¢Âºï...');
            await indexer.indexCodebase(codebasePath);
            console.log('ÂÖ®ÈáèÁ¥¢ÂºïÂÆåÊàê');
        } catch (error) {
            console.error('ÂÖ®ÈáèÁ¥¢ÂºïÂ§±Ë¥•:', error);
            return;
        }
        
        // 2. Â¢ûÈáèÁ¥¢Âºï
        console.log('2. ÊâßË°å reindexByChange...');
        try {
            const stats = await indexer.reindexByChange(codebasePath);
            console.log('reindexByChange ÁªìÊûú:', stats);
        } catch (error) {
            console.error('Â¢ûÈáèÁ¥¢ÂºïÂ§±Ë¥•:', error);
            return;
        }

        // // 3. Ê£ÄÊü•Âø´ÁÖßÊñá‰ª∂
        // const normalizedPath = path.resolve(codebasePath);
        // const hash = require('crypto').createHash('md5').update(normalizedPath).digest('hex');
        // const snapshotDir = path.join(os.homedir(), '.codeindexer', 'merkle');
        // const snapshotFile = path.join(snapshotDir, `code_chunks_${hash.substring(0, 8)}.json`);
        // const exists = fs.existsSync(snapshotFile);
        // console.log('Âø´ÁÖßÊñá‰ª∂Ë∑ØÂæÑ:', snapshotFile);
        // console.log('Âø´ÁÖßÊñá‰ª∂ÊòØÂê¶Â≠òÂú®:', exists);

    } catch (error) {
        console.error('‚ùå Error occurred:', error);
        // Add specific error handling for different services if needed
        process.exit(1);
    } finally {
        // Ê∏ÖÁêÜÂÆöÊó∂Âô®ËµÑÊ∫ê
        // if (embedding) {
        //     embedding.cleanup();
        // }
        // Á°Æ‰øùÁ®ãÂ∫èÊ≠£Â∏∏ÈÄÄÂá∫Ôºå‰∏çÁïô‰∏ãÊÇ¨ÊåÇÁöÑÂÆöÊó∂Âô®
        console.log('Á®ãÂ∫èÊâßË°åÂÆåÊàêÔºåÂç≥Â∞ÜÈÄÄÂá∫');
        
        // Êõ¥Êñ∞ÁªìÊùüÊó∂Èó¥Êà≥‰∏∫‰∏≠ÂõΩÊó∂Èó¥
        const endTimestamp = new Date().toLocaleString('zh-CN', {
            timeZone: 'Asia/Shanghai', 
            year: 'numeric',
            month: '2-digit',
            day: '2-digit',
            hour: '2-digit',
            minute: '2-digit',
            second: '2-digit',
            hour12: false
        }).replace(/[\/-]/g, '-').replace(/[,]/g, ' ');
        
        console.log(`[${endTimestamp}] ==== index codebase ÊµãËØïÂÆåÊàê ====`);
        // Áªô‰∏ÄÁÇπÊó∂Èó¥ËÆ©ÊúÄÂêéÁöÑÊó•ÂøóËæìÂá∫
        setTimeout(() => {
            process.exit(0);
        }, 500);
    }
}

// Run main program
if (require.main === module) {
    main().catch(console.error);
}

export { main };